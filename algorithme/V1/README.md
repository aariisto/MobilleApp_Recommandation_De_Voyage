# SystÃ¨me de Recommandation de Voyages

## ğŸ“Œ Vue d'ensemble

Ce projet utilise l'**intelligence artificielle** pour recommander les meilleures villes en fonction de ce que vous recherchez. Par exemple, si vous aimez les plages et les restaurants, le systÃ¨me vous recommandera les villes cÃ´tiÃ¨res avec une bonne gastronomie.

---

## ğŸ¯ Comment Ã§a fonctionne ?

### **Ã‰tape 1 : Transformer le texte en nombres**

Chaque ville (Paris, Nice, Barcelona, etc.) possÃ¨de des **catÃ©gories** comme :

- Plage ğŸ–ï¸
- Restaurant ğŸ½ï¸
- MusÃ©e ğŸ›ï¸
- Shopping ğŸ›ï¸
- etc.

Le systÃ¨me transforme ces catÃ©gories en **vecteur numÃ©rique** (une liste de nombres) appelÃ© **embedding**. C'est comme une "signature" unique pour chaque ville.

**Exemple :**

```
Paris â†’ "musÃ©e art galerie restaurant" â†’ [0.045, 0.123, -0.087, ..., 0.234]
Nice  â†’ "plage restaurant cafÃ© soleil" â†’ [0.234, 0.156, 0.045, ..., -0.123]
```

### **Ã‰tape 2 : Transformer votre recherche en nombres**

Quand vous dites "Je recherche une plage avec des restaurants", le systÃ¨me fait exactement la mÃªme chose :

```
Votre texte â†’ "plage restaurant" â†’ [0.089, 0.145, -0.056, ..., 0.198]
```

### **Ã‰tape 3 : Comparer et classer**

Le systÃ¨me calcule la **similaritÃ©** entre votre recherche et chaque ville. C'est comme mesurer combien votre souhait ressemble Ã  chaque ville.

La similaritÃ© va de **-1 Ã  1** :

- âœ… **1.0** = Parfaite correspondance
- âœ… **0.5** = Bonne correspondance
- âš ï¸ **0.0** = Aucun rapport
- âŒ **-1.0** = ComplÃ¨tement opposÃ©

Le systÃ¨me classe alors les villes du meilleur au moins bon rÃ©sultat.

### **NouveautÃ© : Gestion des prÃ©fÃ©rences et aversions (Likes & Dislikes)**

Le systÃ¨me supporte maintenant les **dislikes** (ce que vous n'aimez PAS) !

**Formule :**

```
vecteur_final = embedding(likes) - embedding(dislikes)
```

**Comment Ã§a marche :**

- `embedding(likes)` : Ce que vous recherchez (plage, restaurant)
- `embedding(dislikes)` : Ce que vous voulez Ã©viter (montagne, froid)
- La **soustraction** repousse les rÃ©sultats qui contiennent vos dislikes

**Exemple concret :**

```
Vous dites :
  âœ… J'aime : "plage restaurant shopping"
  âŒ Je n'aime pas : "montagne froid noir"

RÃ©sultat :
  âœ… Nice est recommandÃ©e (plage + restaurant)
  âŒ Chamonix est Ã©vitÃ©e (montagne + froid)
```

C'est comme si vous crÃ©iez un "profil de voyage" personnalisÃ© oÃ¹ le systÃ¨me comprend non seulement ce que vous voulez, mais aussi ce que vous voulez Ã©viter absolument.

---

## ğŸ› ï¸ Architecture technique

### **Fichiers principaux**

#### ğŸ“„ `categorie_to_vecteur.py`

CrÃ©e les embeddings (vecteurs) de toutes les villes :

- Se connecte Ã  la base de donnÃ©es PostgreSQL
- RÃ©cupÃ¨re les catÃ©gories de chaque ville
- GÃ©nÃ¨re les embeddings avec le modÃ¨le **MiniLM-L6-v2**
- Stocke les vecteurs dans la colonne `embedding` de la table `cities`

#### ğŸ“„ `teste_algo.py`

Contient l'algorithme de recommandation :

**Fonctions principales :**

1. **`get_all_city_embeddings(conn_params)`**

   - RÃ©cupÃ¨re tous les embeddings depuis PostgreSQL
   - Retourne : `[{id, name, embedding}, ...]`

2. **`get_user_embedding(likes_text, dislikes_text="")`**

   - Convertit votre texte de recherche en embedding
   - Supporte les **likes** (ce que vous aimez) ET les **dislikes** (ce que vous n'aimez pas)
   - Formule : `embedding_final = embedding(likes) - embedding(dislikes)`
   - Exemple simple :
     - `get_user_embedding("plage restaurant")` â†’ `[0.089, 0.145, ...]`
     - `get_user_embedding("plage restaurant", "montagne froid")` â†’ `[0.189, 0.245, ...]` (repousse montagne/froid)

3. **`cosine_similarity(vec1, vec2)`**

   - Calcule la similaritÃ© entre deux vecteurs
   - Formule : `dot(v1, v2) / (||v1|| Ã— ||v2||)`
   - Retourne un score de -1 Ã  1

4. **`rank_cities_by_similarity(user_text, cities, dislikes_text="")`**
   - GÃ©nÃ¨re votre embedding (avec likes et optionnellement dislikes)
   - Compare avec chaque ville
   - Classe les villes par similaritÃ© dÃ©croissante
   - Sauvegarde dans `ranked_cities.json`

### **Fichiers de donnÃ©es**

#### ğŸ“Š `cities_embeddings.json`

Contient les embeddings de toutes les villes (200 villes).

**Format :**

```json
[
  {
    "id": 1,
    "name": "Paris",
    "embedding": [0.061, 0.054, 0.008, -0.125, ...]
  },
  {
    "id": 2,
    "name": "Nice",
    "embedding": [0.234, 0.156, 0.045, -0.089, ...]
  },
  ...
]
```

#### ğŸ“Š `ranked_cities.json`

Contient le rÃ©sultat des recommandations triÃ©es.

**Format :**

```json
[
  {
    "id": 1,
    "name": "Paris",
    "similarity": 0.8234
  },
  {
    "id": 63,
    "name": "The Hague",
    "similarity": 0.7891
  },
  ...
]
```

---

## ğŸ§  Concepts clÃ©s expliquÃ©s simplement

### **Embedding (Vecteur)**

C'est un moyen de reprÃ©senter du texte avec des nombres pour que l'ordinateur puisse le comprendre et le comparer.

**Analogie :**
Un vecteur est comme les coordonnÃ©es GPS d'une ville, mais dans un espace Ã  384 dimensions au lieu de 2 (latitude/longitude).

### **SimilaritÃ© Cosinus**

Mesure l'angle entre deux vecteurs.

- Angle de 0Â° = Vecteurs identiques â†’ SimilaritÃ© = 1.0
- Angle de 90Â° = Vecteurs indÃ©pendants â†’ SimilaritÃ© = 0.0
- Angle de 180Â° = Vecteurs opposÃ©s â†’ SimilaritÃ© = -1.0

**Analogie visuelle :**

```
Vecteur A â†’
               â† Vecteur B (Angle petit = SimilaritÃ© haute)

Vecteur A â†’
            â†‘ Vecteur B (Angle grand = SimilaritÃ© basse)
```

### **ModÃ¨le MiniLM-L6-v2**

Un petit modÃ¨le d'IA prÃ©-entraÃ®nÃ© qui transforme du texte en vecteurs (embeddings).

- LÃ©ger et rapide âš¡
- Produit des vecteurs de 384 dimensions
- Comprend la signification des mots, pas juste les lettres

---

## ğŸ“Š Exemple complet : Pas Ã  pas

**Vous cherchez :** `"plage shopping culture"`

### Ã‰tape 1ï¸âƒ£ : Votre recherche devient un vecteur

```
"plage shopping culture"
  â†“
[0.089, 0.145, -0.056, 0.234, ..., 0.198]  (384 nombres)
```

### Ã‰tape 2ï¸âƒ£ : Comparaison avec Nice

```
Nice a comme catÃ©gories : "plage restaurant cafÃ©"
Nice = [0.234, 0.156, 0.045, 0.123, ..., -0.123]

SimilaritÃ© = dot(votre_vecteur, nice_vecteur) / (norm(votre) Ã— norm(nice))
           = 0.85  âœ… TrÃ¨s bon match !
```

### Ã‰tape 3ï¸âƒ£ : Comparaison avec Berlin

```
Berlin a comme catÃ©gories : "musÃ©e art galerie"
Berlin = [0.012, 0.456, 0.789, 0.345, ..., 0.567]

SimilaritÃ© = 0.62  âœ… Correct match
```

### RÃ©sultat final

```
1. Nice       - 0.85  â† Plage + Shopping + Culture (tous les trois !)
2. Barcelona  - 0.82  â† Plage + Shopping
3. Berlin     - 0.62  â† Culture + Art (pas de plage)
```

---

## ğŸ”§ DÃ©pendances

```
psycopg2          # Connexion PostgreSQL
sentence-transformers  # GÃ©nÃ©ration d'embeddings
numpy             # Calculs mathÃ©matiques
json              # Stockage des rÃ©sultats
```

### Installation

```bash
pip install psycopg2-binary sentence-transformers numpy
```

---

## ğŸ’¡ Points forts de cette approche

âœ… **SÃ©mantique** : Comprend le sens, pas juste les mots-clÃ©s  
âœ… **Scalable** : Fonctionne avec 100 ou 10 000 villes  
âœ… **Rapide** : Embeddings prÃ©-calculÃ©s, pas de calcul Ã  chaque requÃªte  
âœ… **FlexibilitÃ©** : Marche avec n'importe quel texte de recherche  
âœ… **Explicable** : Chaque rÃ©sultat a un score de similaritÃ©

---

## ğŸ“ Pour aller plus loin

- **ModÃ¨les plus grands** : Utiliser `all-mpnet-base-v2` pour plus de prÃ©cision
- **Filtrage** : Ajouter des critÃ¨res (budget, climat, distance)
- **Poids personnalisÃ©s** : Donner plus d'importance Ã  certaines catÃ©gories
- **Clustering** : Grouper les villes similaires
